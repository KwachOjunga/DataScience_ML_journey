{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the column names of a dataset.\n",
    "\n",
    "df['ProductSize'].unique()\n",
    "\n",
    "sizes = 'Large','Large / Medium','Medium','Small','Mini','Compact'\n",
    "\n",
    "df['ProductSize'] = df['ProductSize'].astype('category')\n",
    "df['ProductSize'].cat.set_categories(sizes, ordered=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pytorch Wide Deep**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TabMLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "adult = pd.read_csv(\"data/adult/adult.csv.zip\")\n",
    "adult.columns = [c.replace(\"-\", \"_\") for c in adult.columns]\n",
    "adult[\"income_label\"] = (adult[\"income\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "adult.drop(\"income\", axis=1, inplace=True)\n",
    "\n",
    "for c in adult.columns:\n",
    "    if adult[c].dtype == 'O':\n",
    "        adult[c] = adult[c].apply(lambda x: \"unknown\" if x == \"?\" else x)\n",
    "        adult[c] = adult[c].str.lower()\n",
    "adult_train, adult_test = train_test_split(adult, test_size=0.2, stratify=adult.income_label)\n",
    "\n",
    "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
    "\n",
    "# define the embedding and continuous columns, and target\n",
    "embed_cols = [\n",
    "    ('workclass', 6), \n",
    "    ('education', 8), \n",
    "    ('marital_status', 6), \n",
    "    ('occupation',8), \n",
    "    ('relationship', 6), \n",
    "    ('race', 6)]\n",
    "cont_cols = [\"age\", \"hours_per_week\", \"fnlwgt\", \"educational_num\"]\n",
    "target = adult_train[\"income_label\"].values\n",
    "\n",
    "# prepare deeptabular component\n",
    "tab_preprocessor = TabPreprocessor(embed_cols=embed_cols, continuous_cols=cont_cols)\n",
    "X_tab = tab_preprocessor.fit_transform(adult_train)\n",
    "\n",
    "\n",
    "from pytorch_widedeep.models import TabMlp, WideDeep\n",
    "\n",
    "tabmlp = TabMlp(\n",
    "    mlp_hidden_dims=[200, 100],\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    embed_input=tab_preprocessor.embeddings_input, \n",
    "    continuous_cols=cont_cols,\n",
    "    batchnorm_cont=True,\n",
    ")\n",
    "model = WideDeep(deeptabular=tabmlp)\n",
    "\n",
    "# Model Training\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.metrics import Accuracy\n",
    "\n",
    "trainer = Trainer(model, objective=\"binary\", metrics=[(Accuracy)])\n",
    "trainer.fit(X_tab=X_tab, target=target, n_epochs=5, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TabResnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.models import TabResnet\n",
    "\n",
    "tabresnet = TabResnet(\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    embed_input=tab_preprocessor.embeddings_input, \n",
    "    continuous_cols=cont_cols,\n",
    "    batchnorm_cont=True,\n",
    "    blocks_dims=[200, 100, 100],\n",
    "    mlp_hidden_dims=[100, 50],\n",
    ")\n",
    "model = WideDeep(deeptabular=tabresnet)\n",
    "\n",
    "trainer = Trainer(model, objective=\"binary\", metrics=[(Accuracy)])\n",
    "trainer.fit(X_tab=X_tab, target=target, n_epochs=5, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TabTransformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_cols = [\n",
    "  'workclass', \n",
    "  'education', \n",
    "  'marital_status', \n",
    "  'occupation', \n",
    "  'relationship', \n",
    "  'race'\n",
    "]\n",
    "tab_preprocessor = TabPreprocessor(\n",
    "    embed_cols=embed_cols, \n",
    "    continuous_cols=cont_cols, \n",
    "    for_tabtransformer=True)\n",
    "\n",
    "X_tab = tab_preprocessor.fit_transform(adult_train)\n",
    "\n",
    "\n",
    "from pytorch_widedeep.models import TabTransformer\n",
    "\n",
    "tabtransformer = TabTransformer(\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    embed_input=tab_preprocessor.embeddings_input, \n",
    "    continuous_cols=cont_cols,\n",
    "    shared_embed=True,\n",
    "    num_blocks=3,\n",
    ")\n",
    "model = WideDeep(deeptabular=tabtransformer)\n",
    "\n",
    "\n",
    "trainer = Trainer(model, objective=\"binary\", metrics=[(Accuracy)])\n",
    "trainer.fit(X_tab=X_tab, target=target, n_epochs=5, batch_size=256, val_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
